# [吴恩达课后作业] Course 3.1 and 3.2

### 3.1

1. 有三个评估指标使您很难在两种不同的算法之间进行快速选择，并且会降低您的团队迭代的速度
2. 准确度是一个优化指标; 运行时间和内存大小是令人满意的指标。
3. 尽量保证数据分布相同。
4. 贝叶斯最优误差，我们至少还要一个人们对图片的识别误差值，才能确定选择误差原因。
5. 选择最优的效果作为人类表现。
6. 学习算法的性能可以优于人类表现，但它永远不会优于贝叶斯错误的基准线。
7. 减小偏差可以：尝试减少正则化。训练一个更大的模型，试图在训练集上做得更好。
8. 若训练集和开发集误差小，而开发和测试误差大，可能是开发集太小，或者对开发集过拟合了。
9. 若最后的效果优于人类的表现，那么现在很难衡量可避免偏差，因此今后的进展将会放缓。如果测试集足够大，使得这0.05%的误差估计是准确的，这意味着贝叶斯误差是小于等于0.05的。
10. 若有新的数据出现，应该使用所拥有的数据来定义新的评估指标（使用新的开发/测试集），同时考虑到新物种，并以此来推动团队的进一步发展。
11. 可以适当减少训练样本的数量，提高实验的速度。

### 3.2

1. 首先应该训练一个基本的模型，看看会犯什么错误
2. SoftMax只针对一种可能，只有一种可能出现概率为1其余为0的情况。
3. 进行误差分析的时候，应该重点检查算法分类中出错的图片。
4. 算法学习可以学习有一些未被明确标记的样本。
5. 正如在课堂上看到的那样，分配数据的方式非常重要，您的训练和开发集的分布类似于“现实生活”数据。此外，测试集应包含您实际关心的足够数量的“现实生活”数据。
6. 一位朋友认为训练数据分布比开发/测试分布要容易得多，为了了解这一点，我们必须在两个分布上分别测量人的水平误差，该算法对训练的分布数据有更好的效果。但我们不确定这是因为它被训练在数据上，或者它比开发/测试分布更容易。
7. 如果合成的图像看起来逼真, 就好像您在有雾的天气中添加了有用的数据来识别道路标志和交通信号一样。
8. 你已经在一个庞大的数据集上训练了你的模型，并且她有一个小数据集。 尽管您的标签不同，但您的模型参数已经过训练，可以识别道路和交通图像的许多特征，这些特征对于她的问题很有用。 这对于转移学习来说是一个完美的例子，她可以从一个与您的架构相同的模型开始，改变最后一个隐藏层之后的内容，并使用您的训练参数对其进行初始化。
9. 大训练集端对端效果更好。



